{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb68d890-186f-43ef-8c85-3bf3e20712fe",
   "metadata": {},
   "source": [
    "# Walking\n",
    "The purpose of this notebook is to to refine a policy that has learned to move by trotting around into a policy that wlaks properly.\n",
    "\n",
    "As usual the directory will contain all the necessary for the execution of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea23fef0-3456-4a40-bdb2-be99c52fc965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Sep 28 2025 16:57:08\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from spotmicro.env.spotmicro_env import SpotmicroEnv\n",
    "from reward_function import reward_function, RewardState"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7bb15c-4153-4613-839a-0b1debcc3423",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667ac4c2-12db-432a-98b4-7602eb6e40d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "# ========= CONFIG ==========\n",
    "TOTAL_STEPS = 16_000_000\n",
    "run = \"walk\"\n",
    "base=\"trot\"\n",
    "\n",
    "log_dir = f\"./logs/{run}\"\n",
    "\n",
    "def clipped_linear_schedule(initial_value, min_value=1e-5):\n",
    "    def schedule(progress_remaining):\n",
    "        return max(progress_remaining * initial_value, min_value)\n",
    "    return schedule\n",
    "\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=TOTAL_STEPS // 16,\n",
    "    save_path=f\"{run}_checkpoints\",\n",
    "    name_prefix=f\"ppo_{run}\"\n",
    ")\n",
    "\n",
    "# ========= ENV ==========\n",
    "env = SpotmicroEnv(\n",
    "    use_gui=False,\n",
    "    reward_fn=reward_function, \n",
    "    reward_state=RewardState(),\n",
    "    src_save_file=f\"{base}.pkl\",\n",
    "    dest_save_file=f\"{run}.pkl\"\n",
    ")\n",
    "check_env(env, warn=True)\n",
    "\n",
    "# ========= MODEL ==========\n",
    "model = PPO.load(f\"ppo_{base}\", device = 'cpu')\n",
    "model.set_env(env)\n",
    "model.tensorboard_log = log_dir\n",
    "\n",
    "# Custom logger: ONLY csv + tensorboard (no stdout table)\n",
    "new_logger = configure(log_dir, [\"csv\", \"tensorboard\"])\n",
    "model.set_logger(new_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b907fb-8983-4756-8ed2-be26f4ad2471",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79693176-28e2-4166-b359-8e5f1d2a36bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(\n",
    "    total_timesteps=TOTAL_STEPS,\n",
    "    reset_num_timesteps=False,\n",
    "    callback=checkpoint_callback\n",
    ")\n",
    "model.save(f\"ppo_{run}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4353a413-446d-4b1b-8fbc-0ee4147e1965",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeffb067-676c-41da-b3d7-e2df2e32072e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridges coefficient: 0.25\n",
      "Terminated\n",
      "Terminated\n",
      "Terminated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "X connection to :1 broken (explicit kill or server shutdown).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Intel\n",
      "GL_RENDERER=Mesa Intel(R) HD Graphics 630 (KBL GT2)\n",
      "GL_VERSION=4.6 (Core Profile) Mesa 25.0.7-0ubuntu0.24.04.2\n",
      "GL_SHADING_LANGUAGE_VERSION=4.60\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.6 (Core Profile) Mesa 25.0.7-0ubuntu0.24.04.2\n",
      "Vendor = Intel\n",
      "Renderer = Mesa Intel(R) HD Graphics 630 (KBL GT2)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frame\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: front_left_leg_link_cover\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frame\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: front_right_leg_link_cover\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frame\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: rear_left_leg_link_cover\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: No inertial data for link, using mass=1, localinertiadiagonal = 1,1,1, identity local inertial frame\n",
      "b3Printf: b3Warning[examples/Importers/ImportURDFDemo/BulletUrdfImporter.cpp,126]:\n",
      "\n",
      "b3Printf: rear_right_leg_link_cover\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "unknown parameter type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# === Run rollout ===\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m3001\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     action, _ = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     obs, reward, terminated, truncated, info = env.step(action)\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/spot_micro_project/aea_spot_micro/.venv/lib/python3.12/site-packages/stable_baselines3/common/base_class.py:557\u001b[39m, in \u001b[36mBaseAlgorithm.predict\u001b[39m\u001b[34m(self, observation, state, episode_start, deterministic)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\n\u001b[32m    538\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    539\u001b[39m     observation: Union[np.ndarray, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, np.ndarray]],\n\u001b[32m   (...)\u001b[39m\u001b[32m    542\u001b[39m     deterministic: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    543\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[np.ndarray, Optional[\u001b[38;5;28mtuple\u001b[39m[np.ndarray, ...]]]:\n\u001b[32m    544\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    545\u001b[39m \u001b[33;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[32m    546\u001b[39m \u001b[33;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    555\u001b[39m \u001b[33;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[32m    556\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m557\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/spot_micro_project/aea_spot_micro/.venv/lib/python3.12/site-packages/stable_baselines3/common/policies.py:365\u001b[39m, in \u001b[36mBasePolicy.predict\u001b[39m\u001b[34m(self, observation, state, episode_start, deterministic)\u001b[39m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(observation) == \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation[\u001b[32m1\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    358\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou have passed a tuple to the predict() function instead of a Numpy array or a Dict. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    359\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are probably mixing Gym API with SB3 VecEnv API: `obs, info = env.reset()` (Gym) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    362\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mand documentation for more information: https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html#vecenv-api-vs-gym-api\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    363\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m obs_tensor, vectorized_env = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobs_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m th.no_grad():\n\u001b[32m    368\u001b[39m     actions = \u001b[38;5;28mself\u001b[39m._predict(obs_tensor, deterministic=deterministic)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/spot_micro_project/aea_spot_micro/.venv/lib/python3.12/site-packages/stable_baselines3/common/policies.py:276\u001b[39m, in \u001b[36mBaseModel.obs_to_tensor\u001b[39m\u001b[34m(self, observation)\u001b[39m\n\u001b[32m    273\u001b[39m     \u001b[38;5;66;03m# Add batch dimension if needed\u001b[39;00m\n\u001b[32m    274\u001b[39m     observation = observation.reshape((-\u001b[32m1\u001b[39m, *\u001b[38;5;28mself\u001b[39m.observation_space.shape))  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m obs_tensor = \u001b[43mobs_as_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obs_tensor, vectorized_env\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/spot_micro_project/aea_spot_micro/.venv/lib/python3.12/site-packages/stable_baselines3/common/utils.py:573\u001b[39m, in \u001b[36mobs_as_tensor\u001b[39m\u001b[34m(obs, device)\u001b[39m\n\u001b[32m    565\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    566\u001b[39m \u001b[33;03mMoves the observation to the given device.\u001b[39;00m\n\u001b[32m    567\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    570\u001b[39m \u001b[33;03m:return: PyTorch tensor of the observation on a desired device.\u001b[39;00m\n\u001b[32m    571\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obs, np.ndarray):\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mth\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    575\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {key: th.as_tensor(_obs, device=device) \u001b[38;5;28;01mfor\u001b[39;00m (key, _obs) \u001b[38;5;129;01min\u001b[39;00m obs.items()}\n",
      "\u001b[31mRuntimeError\u001b[39m: unknown parameter type"
     ]
    }
   ],
   "source": [
    "policy = \"walk\"\n",
    "\n",
    "env = SpotmicroEnv(\n",
    "    use_gui=True, \n",
    "    reward_fn=reward_function,\n",
    "    reward_state=RewardState(),\n",
    "    #src_save_file=f\"{policy}.pkl\"\n",
    "    )\n",
    "obs, _ = env.reset()\n",
    "\n",
    "# === Load model ===\n",
    "#model = PPO.load(f\"ppo_{policy}\")\n",
    "model = PPO.load(f\"{policy}_checkpoints/ppo_{policy}_23002176_steps\", device = 'cpu')\n",
    "\n",
    "# === Run rollout ===\n",
    "for _ in range(3001):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "    if terminated or truncated:\n",
    "        print(\"Terminated\")\n",
    "        env.plot_reward_components()\n",
    "        obs, _ = env.reset()\n",
    "    time.sleep(1/60)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eba163-6591-4cd6-98ec-d3e089cf428a",
   "metadata": {},
   "source": [
    "# Results:\n",
    "- n1 was an utter disaster, the gait moved alongisde the ridges (and so perpendicularly to the target direction). Maybe decrease forward reward AND target velocity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
